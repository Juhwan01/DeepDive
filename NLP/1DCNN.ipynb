{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "953eb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6505896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000\n",
    "(X_train,y_train),(X_test,y_test) = datasets.imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2393afe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
      " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
      " list([1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 2, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 2, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 2, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 2, 594, 7, 5168, 94, 9096, 3987, 2, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 2, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 2, 19, 49, 7, 4, 1885, 2, 1118, 25, 80, 126, 842, 10, 10, 2, 2, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 2, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 2, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 2, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 2, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 2, 1775, 3353, 2, 1846, 4, 2, 7, 154, 5, 4, 518, 53, 2, 2, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 1202, 2, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 2, 13, 188, 1076, 3222, 19, 4, 2, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 2, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 2, 804, 2, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 2, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574])\n",
      " list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 2, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113])]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbc2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "X_train = pad_sequences(X_train,maxlen=max_len)\n",
    "X_test = pad_sequences(X_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71c9d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 200), (25000, 200))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7437dbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d204eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "embedding_dim = 256\n",
    "dropout_ratio = 0.3\n",
    "num_filters = 256\n",
    "kernel_size = 3\n",
    "hidden_units =128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352da32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_dim))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Conv1D(num_filters, kernel_size, padding='valid',activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_units, activation='relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae83a46",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ”¢ **1ì¸µ: Embedding Layer**\n",
    "\n",
    "### **ì—­í• **: ì •ìˆ˜ â†’ ì‹¤ìˆ˜ ë²¡í„° ë³€í™˜\n",
    "\n",
    "### **ì²˜ë¦¬ ê³¼ì •**:\n",
    "```python\n",
    "# ì…ë ¥: [14, 22, 16, 43] (ë‹¨ì–´ ì¸ë±ìŠ¤)\n",
    "# ë‚´ë¶€ ì²˜ë¦¬:\n",
    "lookup_table = {\n",
    "    14: [0.1, 0.3, 0.8, 0.2],  # ë‹¨ì–´14ì˜ ì„ë² ë”© ë²¡í„°\n",
    "    22: [0.5, 0.2, 0.1, 0.9],  # ë‹¨ì–´22ì˜ ì„ë² ë”© ë²¡í„°  \n",
    "    16: [0.7, 0.4, 0.6, 0.3],  # ë‹¨ì–´16ì˜ ì„ë² ë”© ë²¡í„°\n",
    "    43: [0.2, 0.8, 0.1, 0.5]   # ë‹¨ì–´43ì˜ ì„ë² ë”© ë²¡í„°\n",
    "}\n",
    "\n",
    "# ì¶œë ¥: [[0.1, 0.3, 0.8, 0.2],\n",
    "#        [0.5, 0.2, 0.1, 0.9], \n",
    "#        [0.7, 0.4, 0.6, 0.3],\n",
    "#        [0.2, 0.8, 0.1, 0.5]]\n",
    "# í˜•íƒœ: (4, 4) â†’ (sequence_length, embedding_dim)\n",
    "````\n",
    "\n",
    "### **í•™ìŠµë˜ëŠ” ê²ƒ**: ê° ë‹¨ì–´ì˜ ì˜ë¯¸ ë²¡í„° (ìœ ì‚¬í•œ ë‹¨ì–´ë¼ë¦¬ ë¹„ìŠ·í•œ ë²¡í„°)\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ¯ **2ì¸µ: Dropout**\n",
    "\n",
    "### **ì—­í• **: ê³¼ì í•© ë°©ì§€\n",
    "\n",
    "### **ì²˜ë¦¬ ê³¼ì •**:\n",
    "\n",
    "```python\n",
    "# ì…ë ¥: [[0.1, 0.3, 0.8, 0.2],\n",
    "#        [0.5, 0.2, 0.1, 0.9],\n",
    "#        [0.7, 0.4, 0.6, 0.3],\n",
    "#        [0.2, 0.8, 0.1, 0.5]]\n",
    "\n",
    "# dropout_ratio=0.2 (20% ë„ê¸°)\n",
    "# ëœë¤í•˜ê²Œ 20% ë‰´ëŸ°ì„ 0ìœ¼ë¡œ ë§Œë“¤ê³  ë‚˜ë¨¸ì§€ëŠ” 1.25ë°° ì¦í­\n",
    "# ì¶œë ¥: [[0.0, 0.375, 1.0, 0.25],\n",
    "#        [0.625, 0.0, 0.125, 1.125],\n",
    "#        [0.875, 0.5, 0.0, 0.375],\n",
    "#        [0.25, 1.0, 0.125, 0.0]]\n",
    "```\n",
    "\n",
    "### **ì£¼ì˜**: í›ˆë ¨í•  ë•Œë§Œ ì‘ë™, ì˜ˆì¸¡í•  ë•ŒëŠ” ëª¨ë“  ë‰´ëŸ° ì‚¬ìš©\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ” **3ì¸µ: Conv1D**\n",
    "\n",
    "### **ì—­í• **: ì—°ì†ëœ ë‹¨ì–´ë“¤ì—ì„œ íŒ¨í„´ ì¶”ì¶œ\n",
    "\n",
    "### **ì²˜ë¦¬ ê³¼ì •** (kernel\\_size=3, num\\_filters=2 ì˜ˆì‹œ):\n",
    "\n",
    "```python\n",
    "# ì…ë ¥: (4, 4) - 4ê°œ ë‹¨ì–´, ê°ê° 4ì°¨ì› ë²¡í„°\n",
    "# í•„í„°1ê³¼ í•„í„°2ê°€ sliding windowì²˜ëŸ¼ ì›€ì§ì„\n",
    "\n",
    "# ìœ„ì¹˜1: [ë‹¨ì–´1, ë‹¨ì–´2, ë‹¨ì–´3]ì— í•„í„° ì ìš©\n",
    "input_window = [[0.1, 0.3, 0.8, 0.2],\n",
    "                [0.5, 0.2, 0.1, 0.9], \n",
    "                [0.7, 0.4, 0.6, 0.3]]\n",
    "\n",
    "filter1 = [[0.1, 0.2, 0.3, 0.4],\n",
    "           [0.5, 0.6, 0.7, 0.8],\n",
    "           [0.9, 1.0, 1.1, 1.2]]\n",
    "\n",
    "result1_pos1 = sum(input_window * filter1) + bias1\n",
    "             = 3.94 â†’ ReLU â†’ 3.94\n",
    "\n",
    "# ìœ„ì¹˜2: [ë‹¨ì–´2, ë‹¨ì–´3, ë‹¨ì–´4]ì— í•„í„° ì ìš©\n",
    "input_window = [[0.5, 0.2, 0.1, 0.9],\n",
    "                [0.7, 0.4, 0.6, 0.3],\n",
    "                [0.2, 0.8, 0.1, 0.5]]\n",
    "\n",
    "result1_pos2 = 2.87\n",
    "\n",
    "# í•„í„°2ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬\n",
    "result2_pos1 = 1.23\n",
    "result2_pos2 = 4.56\n",
    "\n",
    "# ì¶œë ¥: [[3.94, 1.23],\n",
    "#        [2.87, 4.56]]\n",
    "# í˜•íƒœ: (2, 2) â†’ (new_sequence_length, num_filters)\n",
    "```\n",
    "\n",
    "### **í•™ìŠµë˜ëŠ” ê²ƒ**: ê° í•„í„°ê°€ íŠ¹ì • íŒ¨í„´(ì˜ˆ: \"very good\", \"really bad\")ì„ ê°ì§€í•˜ë„ë¡ ê°€ì¤‘ì¹˜ í•™ìŠµ\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ¯ **4ì¸µ: GlobalMaxPooling1D**\n",
    "\n",
    "### **ì—­í• **: ê° í•„í„°ë³„ ìµœëŒ“ê°’ë§Œ ì„ íƒ\n",
    "\n",
    "### **ì²˜ë¦¬ ê³¼ì •**:\n",
    "\n",
    "```python\n",
    "# ì…ë ¥: [[3.94, 1.23],\n",
    "#        [2.87, 4.56]]\n",
    "\n",
    "max_filter1 = max(3.94, 2.87) = 3.94\n",
    "max_filter2 = max(1.23, 4.56) = 4.56\n",
    "\n",
    "# ì¶œë ¥: [3.94, 4.56]\n",
    "# í˜•íƒœ: (2,) â†’ (num_filters,)\n",
    "```\n",
    "\n",
    "### **ì˜ë¯¸**:\n",
    "\n",
    "* í•„í„°1: ë¬¸ì„œì—ì„œ íŒ¨í„´1ì´ ê°€ì¥ ê°•í•˜ê²Œ ë‚˜íƒ€ë‚œ ì •ë„ = 3.94\n",
    "* í•„í„°2: ë¬¸ì„œì—ì„œ íŒ¨í„´2ê°€ ê°€ì¥ ê°•í•˜ê²Œ ë‚˜íƒ€ë‚œ ì •ë„ = 4.56\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§  **5ì¸µ: Dense (ì²« ë²ˆì§¸)**\n",
    "\n",
    "### **ì—­í• **: íŠ¹ì§•ë“¤ì„ ì¡°í•©í•´ì„œ ê³ ì°¨ì› íŒ¨í„´ í•™ìŠµ\n",
    "\n",
    "### **ì²˜ë¦¬ ê³¼ì •**:\n",
    "\n",
    "```python\n",
    "# ì…ë ¥: [3.94, 4.56]\n",
    "# ê°€ì¤‘ì¹˜ W (2x3), í¸í–¥ b (3,)\n",
    "\n",
    "W = [[0.5, 0.3, 0.8],\n",
    "     [0.2, 0.7, 0.4]]\n",
    "b = [0.1, 0.2, 0.3]\n",
    "\n",
    "output = input Ã— W + b\n",
    "       = [2.88, 4.37, 4.97] + [0.1, 0.2, 0.3]\n",
    "       = [2.98, 4.57, 5.27]\n",
    "\n",
    "final_output = [2.98, 4.57, 5.27]\n",
    "```\n",
    "\n",
    "### **í•™ìŠµë˜ëŠ” ê²ƒ**: ì—¬ëŸ¬ í•„í„° ê²°ê³¼ë¥¼ ì¡°í•©í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "\n",
    "## ğŸ¯ **6ì¸µ: Dropout (ë‘ ë²ˆì§¸)**\n",
    "\n",
    "### **ì—­í• **: ë‹¤ì‹œ ê³¼ì í•© ë°©ì§€\n",
    "\n",
    "### **ì²˜ë¦¬ ê³¼ì •**:\n",
    "\n",
    "```python\n",
    "# ì…ë ¥: [2.98, 4.57, 5.27]\n",
    "# 20% ë“œë¡­ì•„ì›ƒ ì˜ˆì‹œ\n",
    "# ì¶œë ¥: [0.0, 5.71, 6.59]  # ì²« ë²ˆì§¸ ë‰´ëŸ°ì´ êº¼ì§€ê³  ë‚˜ë¨¸ì§€ëŠ” 1.25ë°°\n",
    "```\n",
    "\n",
    "\n",
    "## ğŸ“Š **7ì¸µ: Dense (ì¶œë ¥ì¸µ)**\n",
    "\n",
    "### **ì—­í• **: ìµœì¢… ë¶„ë¥˜ ì ìˆ˜ ê³„ì‚°\n",
    "\n",
    "### **ì²˜ë¦¬ ê³¼ì •**:\n",
    "\n",
    "```python\n",
    "# ì…ë ¥: [0.0, 5.71, 6.59]\n",
    "# ê°€ì¤‘ì¹˜ W (3x1), í¸í–¥ b (1,)\n",
    "\n",
    "W = [[0.4],\n",
    "     [0.6], \n",
    "     [0.3]]\n",
    "b = [-1.2]\n",
    "\n",
    "output = [0.0, 5.71, 6.59] Ã— W + b\n",
    "       = 0 + 3.426 + 1.977 - 1.2\n",
    "       = 4.203\n",
    "\n",
    "# Sigmoid í™œì„±í™”\n",
    "probability = 1 / (1 + e^(-4.203))\n",
    "            â‰ˆ 0.985\n",
    "```\n",
    "\n",
    "### **ì˜ë¯¸**: ë¬¸ì¥ì´ ê¸ì •ì¼ í™•ë¥ ì´ 98.5%ë¼ëŠ” ì˜ë¯¸ì˜ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4922c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - acc: 0.7118 - loss: 0.5117\n",
      "Epoch 1: val_acc improved from -inf to 0.87400, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 45ms/step - acc: 0.7119 - loss: 0.5116 - val_acc: 0.8740 - val_loss: 0.2917\n",
      "Epoch 2/20\n",
      "\u001b[1m781/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - acc: 0.9207 - loss: 0.2031\n",
      "Epoch 2: val_acc improved from 0.87400 to 0.88028, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - acc: 0.9207 - loss: 0.2031 - val_acc: 0.8803 - val_loss: 0.2939\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9706 - loss: 0.0865\n",
      "Epoch 3: val_acc improved from 0.88028 to 0.88288, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - acc: 0.9706 - loss: 0.0865 - val_acc: 0.8829 - val_loss: 0.3057\n",
      "Epoch 4/20\n",
      "\u001b[1m781/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9893 - loss: 0.0341\n",
      "Epoch 4: val_acc did not improve from 0.88288\n",
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - acc: 0.9893 - loss: 0.0341 - val_acc: 0.8821 - val_loss: 0.3799\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test,y_test), callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d2784b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - acc: 0.8838 - loss: 0.3054\n",
      "\n",
      " í…ŒìŠ¤íŠ¸ ì •í™•ë„: 0.8829\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n í…ŒìŠ¤íŠ¸ ì •í™•ë„: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80f283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
